{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0535591-44a5-4cc7-8e32-ff64573b74bd",
   "metadata": {},
   "source": [
    "# QField Integration into Machine Learning Landcover Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118a7e98-ce9f-448d-9f2b-6fffa791aef0",
   "metadata": {},
   "source": [
    "Welcome to this interactive notebook! We'll explore how to integrate QField-collected data into a machine learning workflow for landcover classification using **Digital Earth Pacific**.\n",
    "\n",
    "## Notebook Structure\n",
    "\n",
    "This notebook is divided into **three main parts**:\n",
    "\n",
    "<details>\n",
    "<summary><strong>1. Data Preparation</strong></summary>\n",
    "\n",
    "- Define the Area Of Interest (AOI)\n",
    "- Load data from the Digital Earth Pacific Catalog\n",
    "- Interpolate on data points\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><strong>2. Model Training & Validation</strong></summary>\n",
    "\n",
    "- Build a Random Forest classifier\n",
    "- Split data into training, validation, and testing sets\n",
    "- Train and fine-tune the model\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><strong>3. Visualize the Prediction</strong></summary>\n",
    "\n",
    "- Display predictions from the trained model\n",
    "- Compare with validation data\n",
    "</details>\n",
    "\n",
    "\n",
    "## Your Task\n",
    "\n",
    "Follow the notebook and **fill in the missing code** where indicated. Look out for cells marked with `# ⚠️ TODO` or `# Insert your code here`.  \n",
    "Answer the questions Look out for cells marked with `❓ Question for you: `\n",
    "\n",
    "We'll guide you step-by-step. Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f97ece8-21d4-4183-b34d-e9850b1eaf28",
   "metadata": {},
   "source": [
    "## Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b954026-e205-4607-8f3f-b53a5e6cd6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Geospatial and data handling\n",
    "import geopandas as gpd  # For vector data\n",
    "import numpy as np       # Numerical operations\n",
    "import pandas as pd      # Tabular data\n",
    "import xarray as xr      # Multi-dimensional arrays\n",
    "\n",
    "# Distributed computing\n",
    "from dask.distributed import Client as DaskClient\n",
    "\n",
    "# Digital Earth Pacific STAC access\n",
    "from odc.stac import configure_s3_access, load\n",
    "from pystac_client import Client\n",
    "import requests\n",
    "from odc.geo.geom import BoundingBox\n",
    "\n",
    "# Machine Learning\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, cohen_kappa_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Custom utility functions\n",
    "from utils import load_data, mask_cloud, add_indices\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c689c66-7ce7-495a-9c96-1a1417c7bf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 access configured (unsigned)\n",
      "Dask client started with {'tcp://127.0.0.1:35321': 16, 'tcp://127.0.0.1:39679': 16} threads across 2 workers\n"
     ]
    }
   ],
   "source": [
    "# Configure S3 access for Digital Earth Pacific STAC\n",
    "configure_s3_access(aws_unsigned=True)\n",
    "print(\"S3 access configured (unsigned)\")\n",
    "\n",
    "# Set up a Dask client for parallel processing\n",
    "# You can adjust the number of workers and memory based on your system\n",
    "dask_client = DaskClient(\n",
    "    n_workers=2,\n",
    "    threads_per_worker=16,\n",
    "    memory_limit=\"30GB\",\n",
    ")\n",
    "\n",
    "print(f\"Dask client started with {dask_client.nthreads()} threads across {len(dask_client.scheduler_info()['workers'])} workers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6df085-8ba7-4d51-9993-608847cb6d13",
   "metadata": {},
   "source": [
    "## Import Data Catalog\n",
    "\n",
    "We will be using the **Element 84 Earth Search Catalog**, an open **STAC (SpatioTemporal Asset Catalog)** API hosted on **AWS (Amazon Web Services)**.\n",
    "\n",
    "This catalog provides access to a wide range of public Earth observation datasets, including:\n",
    "\n",
    "- **Sentinel-2**\n",
    "- **Landsat**\n",
    "- Other public satellite imagery\n",
    "\n",
    "[Explore the Element 84 STAC Catalog](https://stacindex.org/catalogs/earth-search#/)\n",
    "\n",
    "STAC is a standardized way to describe geospatial assets. It allows us to:\n",
    "\n",
    "- Search for satellite imagery by time, location, and properties\n",
    "- Load data efficiently into our analysis workflows\n",
    "- Interoperate with cloud-native geospatial tools\n",
    "\n",
    "> **Question for you:**  \n",
    "> What types of landcover changes are you most interested in detecting using this data?\n",
    ">\n",
    "> ##### Record your responses here: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cddd45-660d-4d38-a907-fb4531ced563",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84ef645a-c805-4b4f-9cb9-a420da273a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to STAC catalog\n",
      "Found 9 collections:\n",
      "\n",
      "• sentinel-2-pre-c1-l2a\n",
      "• cop-dem-glo-30\n",
      "• naip\n",
      "• cop-dem-glo-90\n",
      "• landsat-c2-l2\n",
      "• sentinel-2-l2a\n",
      "• sentinel-2-l1c\n",
      "• sentinel-2-c1-l2a\n",
      "• sentinel-1-grd\n"
     ]
    }
   ],
   "source": [
    "# Connect to the Element 84 STAC Catalog\n",
    "catalog_url = \"https://earth-search.aws.element84.com/v1/\"\n",
    "client = Client.open(catalog_url)\n",
    "print(\"Connected to STAC catalog\")\n",
    "\n",
    "# List available collections\n",
    "response = requests.get(f\"{catalog_url}collections\")\n",
    "collections = response.json()\n",
    "\n",
    "print(f\"Found {len(collections['collections'])} collections:\\n\")\n",
    "\n",
    "# Display collection IDs\n",
    "for c in collections[\"collections\"]:\n",
    "    print(f\"• {c['id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c11232e-20ad-4648-a655-0bc438551234",
   "metadata": {},
   "source": [
    "## 1. Data Preparation\n",
    "In this section, we will:\n",
    "\n",
    "1.1. **Define the Area of Interest (AOI)**  \n",
    "1.2. **Load and process the following datasets**:\n",
    "   - **Sentinel-2** imagery\n",
    "   - **Spectral Indexes**: NDVI, NDBI\n",
    "   - **Sentinel-1** radar data\n",
    "   - **Elevation Model**  \n",
    "\n",
    "1.3. **Merge all datasets** into a single multiband dataset.  \n",
    "1.4. **Interpolate** the dataset over labeled data points.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43098180-3e41-4ace-83ea-2e3c0aa1367b",
   "metadata": {},
   "source": [
    "### 1.1. Define Area of Interest \n",
    "\n",
    "##### ⚠️ **TODO** : \n",
    "Play with latitude and longitude values to choose your AOI (over Auckland). The example below return an AOI over whole New-Zealand, which is too big."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5782159b-19a1-424e-a5b4-c8cae6da46af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Area of Interest (AOI)\n",
    "# This bounding box covers a small region near Auckland, New Zealand\n",
    "from odc.geo.geom import BoundingBox\n",
    "\n",
    "# ⚠️ TODO : modify value left, bottom, right, top\n",
    "bbox = BoundingBox(\n",
    "    left=165.67,   # Longitude (West)\n",
    "    bottom=-46.94, # Latitude (South)\n",
    "    right=179.22,  # Longitude (East)\n",
    "    top=-33.08     # Latitude (North)\n",
    ")\n",
    "\n",
    "# Explore the AOI interactively\n",
    "bbox.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd169d32-9e08-4369-8e97-2298d3fa249b",
   "metadata": {},
   "source": [
    "### 1.2 Load and Process datasets : \n",
    "\n",
    "### Sentinel-2 Data\n",
    "\n",
    "**Sentinel-2** is a land monitoring mission composed of two satellites that provide high-resolution optical imagery. Key features include:\n",
    "\n",
    "- **Global coverage** every 5 days (or 8 days in the Pacific)\n",
    "- **L2A data** available globally since **January 2017**\n",
    "- **13 spectral bands**:\n",
    "  - 4 visible (RGB)\n",
    "  - 6 Near-Infrared (NIR)\n",
    "  - 3 Short-Wave Infrared (SWIR)\n",
    "\n",
    "#### What We'll Use\n",
    "\n",
    "For this workshop, we will:\n",
    "\n",
    "- Load **Sentinel-2 data from 2024**\n",
    "- Focus on **RGB**, **NIR**, and **SWIR** bands\n",
    "- Compute the **median composite** to:\n",
    "  - Simplify the dataset (no temporal analysis)\n",
    "  - Reduce cloud contamination (a major issue in tropical Pacific regions)\n",
    "\n",
    "**Why median?**  \n",
    "Cloud cover is a persistent challenge in optical satellite imagery. By taking the median across multiple observations, we reduce the impact of clouds and improve data quality for classification.\n",
    "\n",
    "> ❓ **Question for you:**  \n",
    "> Have you worked with Sentinel-2 composites before? What challenges did you face with cloud masking?\n",
    ">\n",
    "> > ##### Record your responses here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3310e3dc-fd86-43a2-b6a2-df4d11a91b13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418beb0e-a07f-4b93-ad39-fbfc2a076df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Sentinel-2 L2A data for the year 2024 over the defined AOI\n",
    "spectral = load_data(\"sentinel-2-l2a\", '2024', bbox)\n",
    "print(\"Sentinel-2 data loaded\")\n",
    "\n",
    "# Apply cloud masking to clean the dataset\n",
    "spectral = mask_cloud(spectral, \"sentinel-2-l2a\")\n",
    "print(\"Cloud masking applied\")\n",
    "\n",
    "# Inspect the dataset\n",
    "print(spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5054a17b-2611-456f-a541-49ca96b2029e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize the Red band from Sentinel-2\n",
    "# This helps us inspect the spatial coverage and quality of the data\n",
    "spectral.red.odc.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09b8841-5f05-40c9-89bd-7f141d3af29e",
   "metadata": {},
   "source": [
    "##### ⚠️ **TODO**:\n",
    "\n",
    "Explore other spectral bands by using the same command as above but changing the bands to:\n",
    "   - green\n",
    "   - near infrared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be953750-564e-4950-be47-699ae88d969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⚠️ TODO : Explore other spectral\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe6ba43-bb61-4f4b-b045-bd567dcbe2a9",
   "metadata": {},
   "source": [
    "> ❓ **Question for you:**  \n",
    "> Do you seen anything specific patterns ?\n",
    "> > ##### Record your responses here: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4321d19d-f6b0-4a6a-a809-705bcdf08043",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9dfed2f-29a5-4fb0-9058-8518c42de956",
   "metadata": {},
   "source": [
    "### Vegetation and Built-up Index\n",
    "\n",
    "Spectral indices are powerful tools for highlighting specific landcover patterns. There are many types — for water, vegetation, wildfire, urban areas, and more.\n",
    "\n",
    "In this workshop, we focus on **two indices** that are particularly useful for analyzing patterns in the Auckland region:\n",
    "\n",
    "### Normalized Difference Vegetation Index (**NDVI**)\n",
    "\n",
    "NDVI helps distinguish **vegetated** from **non-vegetated** areas.\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$NDVI = \\frac{NIR - RED}{NIR + RED}$$\n",
    "\n",
    "- **High NDVI** (close to +1): Dense, healthy vegetation  \n",
    "- **Low or negative NDVI**: Bare soil, built-up areas, or water\n",
    "\n",
    "### Normalized Difference Built-up Index (**NDBI**)\n",
    "\n",
    "NDBI highlights **built-up or impervious surfaces** like buildings and roads.\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$NDBI = \\frac{SWIR - NIR}{SWIR + NIR}$$\n",
    "\n",
    "- **High NDBI**: Urban or built-up areas  \n",
    "- **Low NDBI**: Vegetation or water bodies\n",
    "\n",
    "> **Tip:**  \n",
    "> These indices are derived from Sentinel-2 bands and will be used later to improve landcover classification accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3cc47d-5b1f-48a5-95d3-f5775bed7a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and mask Sentinel-2 data\n",
    "spectral = load_data(\"sentinel-2-l2a\", '2024', bbox)\n",
    "spectral = mask_cloud(spectral, \"sentinel-2-l2a\")\n",
    "\n",
    "# Compute NDVI and NDBI indices\n",
    "spectral_with_indices = add_indices(spectral).compute()\n",
    "\n",
    "# Display the resulting dataset with indices\n",
    "spectral_with_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a50091-0fa0-4867-8215-fa45ebda6665",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize NDVI using an intuitive colormap\n",
    "# The 'RdYlGn' colormap helps distinguish vegetation density:\n",
    "# - Green: High NDVI (dense vegetation)\n",
    "# - Yellow: Moderate NDVI\n",
    "# - Red: Low NDVI (bare soil, urban areas, or water)\n",
    "\n",
    "spectral_with_indices.ndvi.odc.explore(cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0859cfb-5183-4b03-9402-539578f1e953",
   "metadata": {},
   "source": [
    "### Your Turn: Explore Built-up Areas\n",
    "\n",
    "Now that you've seen how NDVI highlights vegetation, let's explore **NDBI**, which helps identify **urban and impervious surfaces**.\n",
    "\n",
    "⚠️ **TODO**  \n",
    "1. Ammend the command `spectral_with_indices.ndvi.odc.explore(cmap=\"RdYlGn\")` to visualize NDBI.  \n",
    "2. Try changing the `cmap` to `\"Greys\"`, `\"OrRd\"`, or `\"inferno\"`\n",
    "\n",
    "> ❓ **Question for you:**  \n",
    "> Which one gives the clearest contrast?\n",
    "\n",
    "> ##### Record your responses here: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c93456a-8c49-467f-b88c-74e455d9f579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b31febe5-822a-4105-8ece-4c9c388dcfb3",
   "metadata": {},
   "source": [
    "Feel free to zoom in and inspect areas that look urban vs vegetated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cfd9c0-42d9-42f0-b8f4-3e45ade005be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⚠️ TODO : Visualize NDBI\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a55407-ecbe-457d-9cc5-e7234ed38d4b",
   "metadata": {},
   "source": [
    "### Sentinel-1: Radar for All Conditions\n",
    "\n",
    "**Sentinel-1** is a dual-satellite mission equipped with **Synthetic Aperture Radar (SAR)**, which operates independently of sunlight and weather conditions, making it ideal for consistent Earth observation.\n",
    "\n",
    "### Key Features:\n",
    "- Operates **day and night**, in **all weather**\n",
    "- Uses **C-band SAR** to measure surface backscatter\n",
    "- Offers **dual polarization**: `VV` (vertical transmit & receive) and `VH` (vertical transmit, horizontal receive)\n",
    "- Sensitive to:\n",
    "  - Surface roughness\n",
    "  - Moisture content\n",
    "  - Viewing geometry\n",
    "\n",
    "> ❓ **Questions for you:**  \n",
    "> How might radar backscatter differ between:\n",
    "> - Forest vs grassland?\n",
    "> - Urban vs water?\n",
    "> - Wet vs dry soil?\n",
    "\n",
    "> ##### Record your responses here: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3842dd-a5fc-4674-8140-7c7eb982fac7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1ae0c45-a48f-4d07-a772-f1454d41db79",
   "metadata": {},
   "source": [
    "We'll explore these differences using Sentinel-1 data next. Ready to load it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b60f646-c3dc-40f8-a716-a324e426bef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Sentinel-1 GRD data for 2024 over the AOI\n",
    "# Sentinel-1 provides radar backscatter data (VV and VH polarizations)\n",
    "\n",
    "radar = load_data(\"sentinel-1-grd\", '2024', bbox)\n",
    "print(\"Sentinel-1 data loaded\")\n",
    "\n",
    "# Apply cloud masking (for consistency, though radar isn't affected by clouds)\n",
    "radar = mask_cloud(radar, \"sentinel-1-grd\")\n",
    "print(\"Cloud masking applied\")\n",
    "\n",
    "# Inspect the radar dataset\n",
    "print(radar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3909014c-fe5b-423e-a95c-45da25dc398d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize Sentinel-1 VV polarization\n",
    "# VV (vertical transmit & receive) is useful for detecting surface texture and moisture.\n",
    "# Try zooming in to see how urban vs vegetated areas differ in radar backscatter.\n",
    "\n",
    "radar.vv.odc.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47779802-45c0-4dcd-83a8-23e95ead110d",
   "metadata": {},
   "source": [
    "### Elevation Model\n",
    "\n",
    "The **Elevation Model** available through the Element 84 catalog provides global terrain data derived from sources like:\n",
    "\n",
    "- **Copernicus DEM**\n",
    "- **NASA’s SRTM**\n",
    "\n",
    "These datasets represent the Earth's surface height in **meters**, and are valuable for:\n",
    "\n",
    "- Topographic analysis\n",
    "- Environmental modeling\n",
    "- Enhancing landcover classification (e.g., distinguishing valleys from ridges)\n",
    "\n",
    "\n",
    "**Why use elevation?**  \n",
    "Elevation can influence vegetation types, urban development, and water flow, making it a useful feature in landcover classification.\n",
    "\n",
    "We'll now load elevation data for our AOI and integrate it into our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3facf9-3f2a-47cb-a27b-1d7e9eb257cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Elevation Data (Copernicus DEM 30m)\n",
    "# Elevation data is static, so no need to specify a year\n",
    "\n",
    "dem_data = load_data(\"cop-dem-glo-30\", None, bbox)\n",
    "\n",
    "# Inspect the elevation dataset\n",
    "dem_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb4db03-b7b9-4a6f-ad4b-9490c78a1788",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize Elevation Data\n",
    "# This shows terrain elevation in meters across the AOI.\n",
    "# Try zooming in to identify valleys, ridges, and flat areas.\n",
    "\n",
    "dem_data.data.odc.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3c8f76-0e96-4214-9f2d-84b3a35ebfd2",
   "metadata": {},
   "source": [
    "### Your Turn: Explore Terrain\n",
    "\n",
    "Now that you've loaded and visualised the elevation data, let's explore how terrain varies across the AOI.\n",
    "\n",
    "> ❓ **Question for you:**\n",
    "> - Where are the **highest elevations**?\n",
    "> - Which areas are **flat or low-lying**?\n",
    "> - How might elevation influence landcover types?\n",
    "> - Can you spot any terrain features that might affect vegetation or urban development?\n",
    "\n",
    "> ##### Record your responses here: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24838b4-3c4f-4cff-b532-9ff5d2f7dbeb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3147022e-4fe8-4c84-94f6-598aafcb9921",
   "metadata": {},
   "source": [
    "### 1.3 Merge all datatasets \n",
    "\n",
    "Now that we've loaded all relevant datasets, including:\n",
    "\n",
    "- Sentinel-2 bands\n",
    "- Spectral indices (NDVI, NDBI)\n",
    "- Sentinel-1 radar (VV & VH)\n",
    "- Elevation model\n",
    "\n",
    "We will **merge** them into a single multiband dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba75747-d805-4a1c-a05c-3abfed1c4b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all datasets into one multiband dataset\n",
    "\n",
    "# Remove the 'time' dimension to simplify merging\n",
    "spectral_with_indices = spectral_with_indices.squeeze(\"time\", drop=True)\n",
    "dem_data = dem_data.squeeze(\"time\", drop=True)\n",
    "radar = radar.squeeze(\"time\", drop=True)\n",
    "\n",
    "# Combine spectral, radar, and elevation data\n",
    "final_data = xr.merge([spectral_with_indices, radar, dem_data])\n",
    "\n",
    "# Rename elevation band for clarity\n",
    "final_data = final_data.rename({\n",
    "    \"data\": \"dem\"  # Rename 'data' to 'dem' for elevation\n",
    "})\n",
    "\n",
    "# Inspect the final merged dataset\n",
    "final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20e5dad-a8b7-491b-b70f-bc2de8c0539c",
   "metadata": {},
   "source": [
    "### 1.4 Interpolation of Data on Label Points \n",
    "\n",
    "### Label Data \n",
    "\n",
    "> ❓ **Questions for you:**  \n",
    "> 1. Looking at the different previous datasets and bands, which specific patterns or features can you identify in each band or index? For example, which band highlights vegetation, water, urban areas, or other landscape features?\n",
    "> 2. Based on the the previous question, what potential land cover classes could be relevant for a future land cover classification over Auckland? Propose four classes.\n",
    "\n",
    "> ##### Record your responses here: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6611c501-804b-45f6-81f6-ba1245f81574",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d6d61bf-8d0e-463e-9fff-9ac73cf2a532",
   "metadata": {},
   "source": [
    "Check if you have the right classes by running the following cell and explore the label points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab50cd3-e3d2-4247-bec4-ad7bf5987f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load label points from GeoPackage\n",
    "# Make sure the file is in the correct location or update the path accordingly\n",
    "gdf = gpd.read_file(\"lulc_auckland_v3.gpkg\").to_crs(final_data.odc.crs)\n",
    "\n",
    "# Print all Land Cover label to check if you were right\n",
    "print(gdf['Land_Cover'].unique())\n",
    "\n",
    "# Explore the label points interactively\n",
    "gdf.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697c5f3a-56bd-4fd4-a903-26c84caff563",
   "metadata": {},
   "source": [
    "The label data points were derived from the Land Cover Database v5.0 available via the LRIS Portal:\n",
    "\n",
    "[LCDB v5.0 - Mainland New Zealand](https://lris.scinfo.org.nz/layer/104400-lcdb-v50-land-cover-database-version-50-mainhese were downloaded as a shapefile and processed using QGIS to fit our needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016a400f-e535-4fb8-a7d7-a114f4c31609",
   "metadata": {},
   "source": [
    "### Why Interpolate?\n",
    "\n",
    "To prepare for model training, we need to assign values from each band to our **label points** (landcover polygons).  \n",
    "We do this using **nearest-neighbor interpolation**, which assigns each label point the value of the **closest pixel** in each band.\n",
    "\n",
    "This step ensures that every labeled point has a complete feature set for classification.\n",
    "\n",
    "> **Tip:**  \n",
    "> Nearest interpolation is fast and simple, but other methods (e.g., bilinear, cubic) may be used for smoother results in other contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c52e7f-6c31-447e-849d-35e404afe6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate multiband data onto label points using nearest-neighbor method\n",
    "sampled = final_data.interp(\n",
    "    x=(\"points\", gdf.geometry.x.values),\n",
    "    y=(\"points\", gdf.geometry.y.values),\n",
    "    method=\"nearest\"\n",
    ")\n",
    "\n",
    "# Clean and format the interpolated dataset\n",
    "df = sampled.to_dataframe().reset_index(drop=True)\n",
    "\n",
    "# Add label information from the original GeoDataFrame\n",
    "df[\"Class_id\"] = gdf[\"Class_id\"].values \n",
    "df[\"Land_Cover\"] = gdf[\"Land_Cover\"].values\n",
    "\n",
    "# Remove unnecessary coordinate reference column\n",
    "df = df.drop([\"spatial_ref\"], axis=1)\n",
    "\n",
    "# Fill missing values with class-wise mean\n",
    "df = df.groupby(\"Class_id\", group_keys=False).apply(lambda g: g.fillna(g.mean(numeric_only=True)))\n",
    "\n",
    "# Summary\n",
    "print(f'Number of labeled points: {len(df)}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e64002-f238-4040-a6fd-8c9e00a28d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all datasets into one multiband dataset\n",
    "\n",
    "# Remove the 'time' dimension to simplify merging\n",
    "spectral_with_indices = spectral_with_indices.squeeze(\"time\", drop=True)\n",
    "dem_data = dem_data.squeeze(\"time\", drop=True)\n",
    "radar = radar.squeeze(\"time\", drop=True)\n",
    "\n",
    "# Combine spectral, radar, and elevation data\n",
    "final_data = xr.merge([spectral_with_indices, radar, dem_data])\n",
    "\n",
    "# Rename elevation band for clarity\n",
    "final_data = final_data.rename({\n",
    "    \"data\": \"dem\"  # Rename 'data' to 'dem' for elevation\n",
    "})\n",
    "\n",
    "# Inspect the final merged dataset\n",
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1414a8c-47e5-407b-90ac-8100ef8a342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load label points from GeoPackage\n",
    "# Make sure the file is in the correct location or update the path accordingly\n",
    "gdf = gpd.read_file(\"lulc_auckland_v3.gpkg\").to_crs(final_data.odc.crs)\n",
    "\n",
    "# Explore the label points interactively\n",
    "gdf.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e217f5-cce5-4c6d-a8ef-8153aeaa9c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate multiband data onto label points using nearest-neighbor method\n",
    "sampled = final_data.interp(\n",
    "    x=(\"points\", gdf.geometry.x.values),\n",
    "    y=(\"points\", gdf.geometry.y.values),\n",
    "    method=\"nearest\"\n",
    ")\n",
    "\n",
    "# Clean and format the interpolated dataset\n",
    "df = sampled.to_dataframe().reset_index(drop=True)\n",
    "\n",
    "# Add label information from the original GeoDataFrame\n",
    "df[\"Class_id\"] = gdf[\"Class_id\"].values \n",
    "df[\"Land_Cover\"] = gdf[\"Land_Cover\"].values\n",
    "\n",
    "# Remove unnecessary coordinate reference column\n",
    "df = df.drop([\"spatial_ref\"], axis=1)\n",
    "\n",
    "# Fill missing values with class-wise mean\n",
    "df = df.groupby(\"Class_id\", group_keys=False).apply(lambda g: g.fillna(g.mean(numeric_only=True)))\n",
    "\n",
    "# Summary\n",
    "print(f'Number of labeled points: {len(df)}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40daf83a-651d-43f9-b244-78ca95d78444",
   "metadata": {},
   "source": [
    "## 2. Model Training: Random Forest Classifier\n",
    "\n",
    "We will now train a **Random Forest** classifier, a powerful and widely used supervised machine learning algorithm.\n",
    "\n",
    "### How It Works:\n",
    "- Builds an **ensemble of decision trees**\n",
    "- Each tree is trained on a **random subset** of the data and features\n",
    "- Final prediction is made by **aggregating** outputs from all trees\n",
    "- Helps reduce **overfitting** and improves **generalization**\n",
    "\n",
    "\n",
    "### Application in Landcover Classification\n",
    "\n",
    "Each pixel (or label point) is assigned a landcover class based on:\n",
    "- Spectral bands (Sentinel-2)\n",
    "- Spectral indices (NDVI, NDBI)\n",
    "- Radar backscatter (Sentinel-1)\n",
    "- Elevation\n",
    "\n",
    "\n",
    "### Model Evaluation Metrics\n",
    "\n",
    "To assess model performance, we’ll use:\n",
    "\n",
    "- **Accuracy**: Proportion of correctly classified samples\n",
    "- **F1-score**: Harmonic mean of precision and recall (useful for imbalanced classes)\n",
    "- **Cohen’s Kappa**: Measures agreement between predicted and true labels, accounting for chance\n",
    "\n",
    "Together, these metrics provide a comprehensive view of how well the model distinguishes landcover types.\n",
    "\n",
    "\n",
    "> ❓ **Question for you:**  \n",
    "> Which metric do you think is most important for landcover classification in your context and why?\n",
    ">\n",
    "> \n",
    "> ##### Record your responses here: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96791aec-1d3b-4485-9814-4e328a341723",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55601595-3758-41c5-ac5d-16a31201e778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the frequency of each unique land cover type in the 'Land_Cover' column\n",
    "# This helps us understand how many times each category appears in the dataset\n",
    "counts = df[\"Land_Cover\"].value_counts()\n",
    "\n",
    "# Display the resulting counts\n",
    "# This will show a Series with land cover types as the index and their respective counts as values\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26af9e6-594a-4a02-8e36-49fda6fde5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the list of possible features for training a model\n",
    "# We use slicing to exclude the last 4 columns from the list of all column names\n",
    "print(f'Possible features for training:\\n {df.columns.values[:-4]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3721029c-28d2-49c2-8502-4c6e3877c0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input features for the model.\n",
    "# These are spectral bands and derived indices commonly used in remote sensing:\n",
    "# - 'red', 'blue', 'green', 'nir08', 'swir16': spectral bands\n",
    "# - 'ndvi', 'ndbi': vegetation and built-up indices\n",
    "# - 'vh', 'vv': radar backscatter values\n",
    "# - 'dem': elevation data\n",
    "features = df[['red', 'blue', 'green', 'nir08', 'swir16', 'ndvi', 'ndbi', 'vh', 'vv', 'dem']]\n",
    "\n",
    "# Define the target labels for classification.\n",
    "# 'Class_id' represents the land cover class each sample belongs to.\n",
    "labels = df['Class_id']\n",
    "\n",
    "# Split the dataset into training and validation sets.\n",
    "# - 80% of the data is used for training\n",
    "# - 20% is used for validation\n",
    "# - random_state ensures reproducibility of the split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    features, labels, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb2f82e-be7c-4f3d-ad98-7d973a43d08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest model with 400 decision trees (n_estimators), a fixed random seed for reproducibility and 'balanced' class weights to handle class imbalance by adjusting weights inversely proportional to class frequencies\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=400,\n",
    "    random_state=42,\n",
    "    class_weight='balanced')\n",
    "\n",
    "# Train the model using the training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained model to predict land cover classes for the validation set\n",
    "y_pred = rf.predict(X_val)\n",
    "\n",
    "# Calculate accuracy: proportion of correctly predicted samples\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "# Calculate weighted F1-score: harmonic mean of precision and recall, weighted by support of each class\n",
    "f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "# Calculate Cohen's Kappa: measures agreement between predicted and true labels, adjusted for chance\n",
    "kappa = cohen_kappa_score(y_val, y_pred)\n",
    "\n",
    "# Generate a detailed classification report: includes precision, recall, F1-score, and support for each class\n",
    "report = classification_report(y_val, y_pred)\n",
    "\n",
    "# Display Results\n",
    "print(\"Random Forest Classifier Performance\")\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n",
    "print(f\"Weighted F1-score: {f1:.2%}\")\n",
    "print(f\"Cohen's Kappa: {kappa:.3f}\")\n",
    "print(\"\\nClassification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12acd965-e6f8-4100-bb64-2dd1050f5f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of features used during training\n",
    "train_features = ['red', 'blue', 'green', 'nir08', 'swir16', 'ndvi', 'ndbi', 'vh', 'vv', 'dem']\n",
    "\n",
    "# Assume 'final_data' is an xarray.Dataset containing the raster layers for prediction\n",
    "datasets = final_data\n",
    "\n",
    "# Check if all required features are present in the dataset\n",
    "missing_features = [f for f in train_features if f not in datasets.data_vars]\n",
    "if missing_features:\n",
    "    raise ValueError(f\"Missing features in the dataset: {missing_features}\")\n",
    "\n",
    "# Stack all feature layers into a single NumPy array\n",
    "# Each layer is squeezed to remove singleton dimensions\n",
    "# The result is a 3D array with shape: (bands, height, width)\n",
    "stacked = np.stack([np.squeeze(datasets[f].values) for f in train_features], axis=0)\n",
    "\n",
    "# Extract dimensions\n",
    "bands, ysize, xsize = stacked.shape\n",
    "\n",
    "# Reshape the stacked array into a 2D array for prediction\n",
    "# Shape becomes (num_pixels, num_features)\n",
    "X_test = stacked.reshape(bands, -1).T\n",
    "\n",
    "# Identify valid pixels (i.e., those without NaNs or infinite values)\n",
    "valid_mask = np.all(np.isfinite(X_test), axis=1)\n",
    "\n",
    "# Filter out invalid pixels for prediction\n",
    "X_valid = X_test[valid_mask]\n",
    "\n",
    "# Initialize an array to hold predictions for all pixels and fill with NaNs initially\n",
    "pred_flat = np.full(X_test.shape[0], np.nan)\n",
    "\n",
    "# Predict land cover class only for valid pixels\n",
    "pred_flat[valid_mask] = rf.predict(X_valid)\n",
    "\n",
    "# Convert the flat prediction array back to the original spatial dimensions\n",
    "pred_raster = pred_flat.reshape(ysize, xsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d41f35-a598-4f8b-99f4-43665a8b5aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the importance scores for each feature\n",
    "# These scores indicate how much each feature contributed to the model's decision-making\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Get the names of the features used during training\n",
    "feature_names = features.columns\n",
    "\n",
    "# Create a DataFrame to organize and display feature importances\n",
    "# Sort the features in descending order of importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the Feature Importance Table\n",
    "\n",
    "print(\"\\nFeature Importances:\")\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b783fd6-f674-4de4-990e-f4a78d42fdae",
   "metadata": {},
   "source": [
    "## Your Turn: Interpret Feature Importance and Validate Prediction\n",
    "\n",
    "Now that you've generated the importance table, let's explore the features and and it's implications.\n",
    "\n",
    "> ❓ **Question for you:**\n",
    "> - What are the **top 3 most important features**? Why these features might be critical for distinguishing land cover classes\n",
    "> - How do these features relate to the spectral or radar properties of different land cover types? Example: Why might `ndvi` be important for vegetation?\n",
    ">\n",
    "> \n",
    "> ##### Record your responses here: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d819027-6f8a-47c9-a622-47d90c571818",
   "metadata": {},
   "source": [
    "\n",
    "> ##### Record your responses here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9796c82-26d0-4797-8eff-08be2fe9d35c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f73dc77-fcac-47e7-a0e5-205dc21a798e",
   "metadata": {},
   "source": [
    "## 3. Visualize Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fe41ea-c944-42e3-ac06-afc136b11ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the red, green, and blue bands to float32 for consistency\n",
    "red = datasets[\"red\"].astype(\"float32\")\n",
    "green = datasets[\"green\"].astype(\"float32\")\n",
    "blue = datasets[\"blue\"].astype(\"float32\")\n",
    "\n",
    "# Stack the three bands along the last axis to create an RGB image, the resulting shape will be (height, width, 3)\n",
    "rgb = np.stack([red, green, blue], axis=-1)\n",
    "\n",
    "# Normalize the RGB values using the 99th percentile - this enhances contrast by reducing the influence of extreme values\n",
    "rgb_norm = np.clip(rgb / np.percentile(rgb, 99), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178f601f-c14c-43e7-8e9e-82df2c6bcddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping class IDs to descriptive names\n",
    "class_labels = {\n",
    "    1: \"Forest\",\n",
    "    2: \"Settlement\",\n",
    "    3: \"Water\",\n",
    "    4: \"Grassland/Shrubland\"\n",
    "}\n",
    "\n",
    "# Define colors for each class in the visualization\n",
    "colors = [\n",
    "    \"darkgreen\",   # Forest\n",
    "    \"grey\",        # Settlement\n",
    "    \"darkblue\",    # Water\n",
    "    \"lightgreen\"   # Grassland/Shrubland\n",
    "]\n",
    "\n",
    "# Create a colormap using the defined colors\n",
    "cmap = ListedColormap(colors)\n",
    "\n",
    "# Create a figure with two side-by-side subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Left subplot: RGB composite\n",
    "axes[0].imshow(rgb_norm)\n",
    "axes[0].set_title(\"RGB Composite\", fontsize=14)\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "# Right subplot: Predicted land cover map\n",
    "im = axes[1].imshow(pred_raster, cmap=cmap)\n",
    "axes[1].set_title(\"Predicted Land Cover\", fontsize=14)\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "# Add a legend for land cover classes\n",
    "patches = [Patch(color=colors[i-1], label=class_labels[i]) for i in class_labels]\n",
    "axes[1].legend(\n",
    "    handles=patches,\n",
    "    bbox_to_anchor=(1.05, 1),\n",
    "    loc=\"upper left\",\n",
    "    title=\"Land Cover\",\n",
    "    fontsize=10\n",
    ")\n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ed71ce-bb52-4a03-98f9-9e9df24b2c29",
   "metadata": {},
   "source": [
    "> **Question for you:**\n",
    "> - Compare the **RGB composite** and the **predicted land cover map**. Do the predictions make sense visually? Identify areas where the model might have misclassified land cover.\n",
    "\n",
    "> ##### Record your responses here: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9be1f34-56cd-4402-bc37-f431fe3e2b5d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1adc4b-dabd-4a5e-9409-82e4ad064b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the figure to a file\n",
    "fig.savefig(\"predicted_land_cover.png\", dpi=300, bbox_inches=\"tight\")\n",
    "print(\"Figure exported as 'predicted_land_cover.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba5f6f8-039e-4880-9bc4-cace643d57f7",
   "metadata": {},
   "source": [
    "⚠️ **TODO**\n",
    "   - Remove the least important feature(s) from the dataset.\n",
    "   - Retrain the Random Forest model.\n",
    "   - Compare accuracy and F1-score before and after feature removal.\n",
    "   - What changed? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104a622d-850c-4e96-b22b-b24f08bef7cf",
   "metadata": {},
   "source": [
    "## 4. Conclusion \n",
    "\n",
    "This workshop demonstrated a complete workflow for integrating QField-collected data into a machine learning pipeline for landcover classification using Digital Earth Pacific tools. By leveraging multi-source Earth observation datasets such as **Sentinel-2 optical imagery, Sentinel-1 radar, and Copernicus elevation models**, we built a rich feature set to train a Random Forest classifier.\n",
    " \n",
    "### Key Achievements\n",
    " \n",
    "- **Comprehensive Data Preparation**: Defined an Area of Interest (AOI) over Auckland and processed spectral bands, vegetation and built-up indices (NDVI, NDBI), radar backscatter, and elevation data.\n",
    "- **Model Training and Evaluation**: Trained a Random Forest model using interpolated features at labeled points and evaluated its performance using accuracy, F1-score, and Cohen’s Kappa. The model showed strong predictive capability across four landcover classes: *Forest*, *Settlement*, *Water*, and *Grassland/Shrubland*.\n",
    "- **Feature Importance Analysis**: NDVI, elevation, and radar backscatter emerged as top contributors, underscoring the value of combining optical, radar, and topographic data.\n",
    " \n",
    "### Balancing Features and Training Points\n",
    " \n",
    "A critical consideration in this workflow is the trade-off between the number of features and the number of labeled training points. While adding more features (e.g., spectral bands, indices, radar layers) can improve model expressiveness and accuracy, it also increases the dimensionality of the data. If the number of labeled points is too small relative to the number of features, the model risks **overfitting**, learning noise instead of general patterns.\n",
    " \n",
    "To mitigate this:\n",
    " \n",
    "- Ensure enough labeled samples for each landcover class.\n",
    "- Consider feature selection or dimensionality reduction to retain only the most informative features.\n",
    "- Use balanced class weights and robust validation metrics to assess generalization.\n",
    " \n",
    "This balance is especially important in Pacific Island contexts, where labelled data may be limited but environmental diversity is high.\n",
    " \n",
    "### Final Thoughts\n",
    " \n",
    "This notebook provides a practical and scalable approach to landcover classification using open-source tools and cloud-native geospatial data. Participants are encouraged to experiment further; refining AOIs, testing alternative models, and exploring temporal dynamics, to enhance environmental monitoring and decision-making across the region.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
